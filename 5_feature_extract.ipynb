{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取图片特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import applications\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GlobalAveragePooling2D, Flatten\n",
    "import h5py\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考：https://keras.io/preprocessing/image/\n",
    "# 参考：https://github.com/ypwhs/dogs_vs_cats\n",
    "def get_img_xception_feature(batch_size_in=32,img_size_in =(299,299,3)):\n",
    "    feature_file = \"modelfile/xception_bottleneck.h5\"\n",
    "    if(os.path.exists(feature_file)):\n",
    "        raise Exception(\"file already exists: \\\"\"+ feature_file +\"\\\". If you need to extract features again, remove the file first.\") \n",
    "    if not os.path.exists(\"modelfile/\"):\n",
    "        os.mkdir(\"modelfile/\")\n",
    "    \n",
    "    x_tensor = Input(img_size_in)\n",
    "    \n",
    "    \"\"\"\n",
    "    datagen =  ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        rotation_range=0.0,\n",
    "        width_shift_range=0.0,\n",
    "        height_shift_range=0.0,\n",
    "        shear_range=0.0,\n",
    "        zoom_range=0.0,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip = True,\n",
    "        rescale=1. / 255,\n",
    "        data_format='channels_last'  #形如（128,128,3）\n",
    "    )\n",
    "    \"\"\"\n",
    "    datagen =  ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    \n",
    "    base_model = applications.Xception(input_tensor = x_tensor,weights='imagenet', include_top=False)\n",
    "    #GlobalAveragePooling2D:输出(samples,2048); Flatten:输出(samples,204800)，Flatten保存的数据太大了，弃之不用；\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output)) #添加GlobalAveragePooling2D层\n",
    "    # 验证集暂时不与训练集分开\n",
    "    # 图片预处理，参考：https://keras-cn.readthedocs.io/en/latest/preprocessing/image/\n",
    "    train_generator = datagen.flow_from_directory(\"processed_train_data\", img_size_in[:2], shuffle=False, \n",
    "                                              batch_size=batch_size_in, class_mode='categorical')\n",
    "    \n",
    "    test_generator = datagen.flow_from_directory(\"processed_test_data\", img_size_in[:2], shuffle=False, \n",
    "                                             batch_size=batch_size_in, class_mode=None)\n",
    "    # 参考 https://keras.io/models/model/\n",
    "    train_features = model.predict_generator(train_generator, None,verbose=1) #train_generator.samples)\n",
    "    test_features = model.predict_generator(test_generator, None,verbose=1) #test_generator.samples)\n",
    "    \n",
    "    test_file_que = []\n",
    "    for i, fname in enumerate(test_generator.filenames):\n",
    "        test_file_que.append(fname.encode('utf8'))\n",
    "    \n",
    "    train_file_que =[]\n",
    "    for i, fname in enumerate(train_generator.filenames):\n",
    "        train_file_que.append(fname.encode('utf8'))\n",
    "    \n",
    "    with h5py.File(feature_file) as h:\n",
    "        h.create_dataset(\"train_features\", data=train_features)\n",
    "        h.create_dataset(\"test_features\", data=test_features)\n",
    "        h.create_dataset(\"train_label\", data=train_generator.classes)\n",
    "        h.create_dataset(\"test_file_que\",data=test_file_que)\n",
    "        h.create_dataset(\"train_file_que\",data=train_file_que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34905 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "1091/1091 [==============================] - 741s 679ms/step\n",
      "391/391 [==============================] - 266s 680ms/step\n"
     ]
    }
   ],
   "source": [
    "get_img_xception_feature(batch_size_in=32,img_size_in =(299,299,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#有时候需要用来备份现有文件\n",
    "oldfile = \"modelfile/xception_bottleneck.h5\"\n",
    "newfile = \"modelfile/xception_bottleneck_bak.h5\"\n",
    "#os.rename(oldfile,newfile)\n",
    "#shutil.copy(oldfile,newfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
